name: Continuous Benchmarking


on:
  push:
    branches: [master]

    
permissions:
  contents: write
  deployments: write


jobs: 
  benchmark:
    name: Run C Benchmarks
    runs-on: self-hosted

    steps:
      - name: Setup Java JDK
        uses: actions/setup-java@v1.4.3
        with:
          java-version: 14
 
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8

      - name: Checkout Lingua Franca repository
        uses: actions/checkout@v2
        with:
          repository: LDeng0205/lingua-franca
          submodules: true
        
      - name: Install Python dependencies
        run: pip3 install -r benchmark/runner/requirements.txt  

      - name: Build lfc
        run: |
          ./gradlew buildLfc

      # LF BENCHMARK RUN
      - name: Set LF_PATH
        run: |
          echo "LF_PATH=$GITHUB_WORKSPACE" >> $GITHUB_ENV
      - name: Run C Benchmarks
        run: |
          python3 benchmark/runner/run_benchmark.py -m test_mode=False iterations=5 benchmark="glob(*)" target=lf-c continue_on_error=True json=True
      
      # Use continuous benchmark action to store result
      - name: Store Benchmark Result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: Lingua Franca C target Benchmark
          tool: customSmallerIsBetter
          output-file-path: multirun/benchmark_result.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true

          # Show alert with commit comment on detecting possible performance regression
          alert-threshold: '200%' 
          comment-on-alert: false
          fail-on-alert: false
          